# True Future Rating (TFR) Algorithm - Complete Rebuild Summary

**Date Completed:** February 1, 2026
**Status:** ‚úÖ Phase 1 Complete - Production Ready (98% satisfied, 2% future tuning)

---

## üéØ Project Objective

Rebuild the TFR algorithm from scratch as a **pure peak/ceiling projection system** that projects what a prospect's **age-27 peak season** would look like if everything goes right. Remove all confidence penalties and regressions - embrace that TFR represents upside, not likelihood.

---

## üèóÔ∏è Core Algorithm Design

### Philosophy Shift

**OLD (Confidence-Based):**
- Applied regression toward replacement level based on "confidence"
- Penalized prospects for uncertainty
- Created philosophical confusion (is this ceiling or expected value?)

**NEW (Pure Peak Projection):**
- Projects age-27 peak season assuming full development
- No confidence penalties or regression
- Accept that many won't reach ceiling - that's prospect risk, not rating error
- Success measured by **distribution alignment**, not individual accuracy

### Algorithm Flow

1. **Calculate Level-Weighted IP** for scouting weight determination
   - AAA: 1.0x (full weight)
   - AA: 0.7x (100 IP = 70 "AAA-equivalent")
   - A: 0.4x (100 IP = 40 "AAA-equivalent")
   - R: 0.2x (100 IP = 20 "AAA-equivalent")

2. **Determine Scouting Weight** based on weighted IP
   - < 75 weighted IP ‚Üí 100% scout
   - 76-150 weighted IP ‚Üí 80% scout
   - 151-250 weighted IP ‚Üí 70% scout
   - 250+ weighted IP ‚Üí 60% scout

3. **Blend Scouting + Stats** separately per component
   - Stuff ‚Üí K9
   - Control ‚Üí BB9
   - HRA ‚Üí HR9

4. **Rank all prospects** by each component ‚Üí percentiles

5. **Map component percentiles** to MLB peak-age distributions (2015-2020, ages 25-29)

6. **Calculate FIP** from mapped rates with clamping:
   - K9: 3.0 to 11.0 (allows elite strikeout ceiling)
   - BB9: 0.85 to 7.0 (best observed: 0.89)
   - HR9: 0.20 to 2.5 (Dave Larocque 2020: 0.2 in 123 IP)

7. **Rank by FIP** for final TFR rating

---

## üé≤ Peak Workload Projections

Updated IP formulas to reflect **peak season workloads**, not career averages:

### TeamRatingsService (Farm Rankings):
```typescript
baseIp = 30 + (stamina √ó 3.0)
// Stamina 50 ‚Üí 180 IP, 60 ‚Üí 210 IP, 70 ‚Üí 240 IP
```

### ProjectionService (Player Profile):
```typescript
baseIp = 10 + (stamina √ó 3.0)
// Plus skill modifiers (elite gets 1.20x)
// Plus elite boost (FIP < 3.0 gets 1.08x)
```

**Result:** Elite prospects (70+ stamina) now project to 220-250 IP, matching real MLB workhorses.

---

## üìä TFR Rating Scale (Final)

Half-point scale based on FIP percentile ranking:

| TFR | Percentile Range | % of Prospects | Count (of ~1000) |
|-----|------------------|----------------|------------------|
| **5.0** | 99-100% | 1% | ~10 |
| **4.5** | 97-99% | 2% | ~20 |
| **4.0** | 93-97% | 4% | ~40 |
| **3.5** | 75-93% | 18% | ~180 |
| **3.0** | 60-75% | 15% | ~150 |
| **2.5** | 35-60% | 25% | ~250 |
| **2.0** | 20-35% | 15% | ~150 |
| **1.5** | 10-20% | 10% | ~100 |
| **1.0** | 5-10% | 5% | ~50 |
| **0.5** | 0-5% | 5% | ~50 |

**Key:** Top 70 prospects (4.0+) represent elite tier. Largest tier is 2.5 (organizational depth/lottery tickets).

---

## üî¨ Validation Results

Tested against 2017 prospects ‚Üí 2021 outcomes:

### Distribution Alignment: **100/100 scores**
- FIP: Mean 4.34 vs 4.33, Median 4.29 vs 4.32
- K9: Mean 6.22 vs 6.22 (0.00 difference!)
- BB9: Mean 2.63 vs 2.69
- HR9: Mean 0.95 vs 0.94
- All percentile targets within 0.15 FIP

**Philosophy:** We're not trying to predict individual outcomes (that would always fail for ceiling projections). We're validating that **groups of prospects align to reality** - elite tier projects to elite MLB level, etc.

---

## üõ°Ô∏è Outlier Protection (Three-Layer Defense)

### 1. Filter MLB Distribution Data
- Require 50+ IP minimum
- Ages 25-29 only (peak years)
- Validate rates: K9[2-15], BB9[0.5-8], HR9[0.2-3]

### 2. Clamp Projected Rates
Based on actual MLB extremes:
- **K9: 3.0 to 11.0** (MLB max 9.79, allow ceiling)
- **BB9: 0.85 to 7.0** (best observed: 0.89)
- **HR9: 0.20 to 2.5** (Dave Larocque 2020: 0.2 HR/9)

### 3. Display Clamping (UI Only)
- True Ratings display max 80 on 20-80 scale
- Backend keeps actual values for calculations
- Matches OOTP's approach of hiding extreme overages

**Result:** Prevents absurd projections (17.64 K9, 0.00 HR9) while allowing generational talent to reach realistic extremes.

---

## üí° Key Design Decisions & Rationale

### 1. Why Level-Weighted IP?
**Problem:** 149 IP in Rookie ‚â† 149 IP in AAA for reliability

**Solution:** Weight IP by level before applying scouting weight thresholds. Recognizes that higher-level stats are more reliable and prevents low-level bulk IP from overwhelming scouting.

### 2. Why No Confidence Regression?
**Problem:** Regression created philosophical confusion and penalized upside

**Solution:** Pure peak projection. TFR = ceiling if everything goes right. Accept that many won't reach ceiling - that's prospect risk, not rating error. Measure success via distribution alignment, not individual accuracy.

### 3. Why Component Separation?
**Problem:** Blending into single FIP early loses information

**Solution:** Track Stuff/Control/HRA separately through the entire pipeline. Each component is mapped independently to MLB distribution, then combined. More accurate than single-FIP approach and provides diagnostic value.

### 4. Why Peak-Age Filtering (25-29)?
**Problem:** We're projecting age-27 peak, not career average

**Solution:** Map prospect percentiles to MLB pitchers at their peak ages (25-29), not all ages. This ensures we're comparing peaks to peaks. Critical for accuracy.

### 5. Why Allow Extreme Projections?
**Example:** Bong-hwan Park (80/80/80 OSA scouting) ‚Üí 2.02 FIP, 9.1 WAR

**Rationale:** If OSA says a prospect is 80/80/80 (elite at ALL three phases), the math SHOULD produce extreme results. No real pitcher achieved it because no real pitcher was 80/80/80. That's OSA's optimism, not our system's error. The rarity is appropriate - it's what makes the #1 prospect special.

---

## üîß Technical Implementation

### Files Modified

**Core Algorithm:**
- `src/services/TrueFutureRatingService.ts` - Complete rebuild
  - Added level-weighted IP constants
  - Added MLB distribution builder with peak-age filtering
  - Added percentile ranking functions
  - Added percentile ‚Üí MLB mapping with clamping
  - Removed all confidence logic
  - Made async to load MLB DOB data

**Peak Workload Calculations:**
- `src/services/TeamRatingsService.ts` - Updated IP formulas for Farm Rankings display
- `src/services/ProjectionService.ts` - Updated IP formulas for Player Profile projections

**Display & UI:**
- `src/views/TrueRatingsView.ts` - Updated for async TFR, display clamping, rating conversions
- `src/views/FarmRankingsView.ts` - Added export with percentile data
- `src/views/PlayerProfileModal.ts` - Updated for async TFR, display clamping, peak ratings in bars
- `src/views/PlayerRatingsCard.ts` - Added display clamping helper
- `src/views/GlobalSearchBar.ts` - Updated for async TFR calls
- `src/views/StatsView.ts` - Updated for async TFR calls

**WAR Calculations:**
- `src/services/PotentialStatsService.ts` - Removed WAR multiplier (peak projections don't need boost)
- `src/views/PlayerProfileModal.ts` - Use 2020 league context consistently for all peak projections

---

## üìà Validation Philosophy

### ‚ùå WRONG Metrics:
```
Individual MAE on projections
"Jon's projected 3.50 vs actual 4.20 = error 0.70"
‚Üí This will ALWAYS be high for ceiling projections
```

### ‚úÖ RIGHT Metrics:
```
1. Distribution alignment
   - Elite tier (TFR 4.5+) averages to elite MLB level
   - Above-avg tier averages to above-avg MLB level

2. MLB arrival rates
   - Higher TFR = higher arrival %
   - Tier differences should be significant

3. Performance correlation (grouped)
   - Projected vs actual FIP by TFR tier
   - Not individual MAE
```

**Success = groups align to reality, not individuals**

---

## üéØ Known Limitations & Future Work

### Current Limitations
1. **No historical scouting data** - Can only project current year
2. **Single-model approach** - No ensemble yet
3. **No injury risk modeling** - Peak assumes healthy season
4. **No development curve modeling** - Binary "will they reach peak or not"

### Future Enhancements (2% remaining)
1. **Historical scouting integration** - If year-by-year scouting becomes available
2. **Parameter tuning** - Fine-tune level weights (AAA=1.0, AA=0.7, A=0.4, R=0.2) if needed
3. **IP threshold adjustment** - Adjust 75/150/250 thresholds based on more validation
4. **Ensemble approach** - Multiple projection models combined
5. **Development probability** - Model likelihood of reaching peak (separate from peak itself)

---

## üìù Example Projections

### Elite Prospect (Bong-hwan Park, Age 20, SP)
**OSA Scouting:** 80/80/80 (generational talent)
**TFR:** 5.0 (99th percentile, #1 prospect)
**Peak Projection (Age 27):**
- FIP: 2.02 (elite, mathematically correct for 80/80/80)
- K9: 9.22, BB9: 0.85, HR9: 0.22
- IP: 240, WAR: 9.1
- **True Ratings Display:** 80/80/80 (bars show peak, not current)

### Above-Average Prospect (Typical 4.0 TFR)
**Peak Projection:**
- FIP: ~3.80-4.00
- K9: ~7.5, BB9: ~2.5, HR9: ~1.0
- IP: ~180-200, WAR: ~3.5-4.5

### Fringe Prospect (Typical 3.0 TFR)
**Peak Projection:**
- FIP: ~4.50-4.70
- K9: ~6.0, BB9: ~3.5, HR9: ~1.2
- IP: ~150-170, WAR: ~1.5-2.5

---

## üöÄ Production Readiness

**Status:** ‚úÖ Ready for production use

**Confidence Level:** 98% satisfied
- Core algorithm validated and working correctly
- Distribution alignment is excellent (100/100 scores)
- Outlier protection prevents absurd projections
- UI correctly displays peak ratings
- WAR calculations consistent across views

**Remaining 2%:** Fine-tuning that can wait for final pre-1.0 testing
- Minor parameter adjustments if needed
- Edge case discovery through real-world usage
- Potential ensemble modeling in future

---

## üí≠ Philosophy Summary

TFR is a **ceiling projection tool**, not a **probability-weighted forecast**. It answers the question:

> "If this prospect develops perfectly and reaches his peak at age 27, what would that season look like?"

It does NOT answer:
- "What's the expected value?" (That requires probability of reaching peak)
- "What will his rookie season look like?" (That's a different projection)
- "Will he make the majors?" (That's an arrival probability model)

**Success is measured by whether groups of prospects align to MLB reality**, not whether individuals hit their projections. A 5.0 TFR prospect who becomes a 3.5 WAR pitcher isn't a "failed projection" - he's a prospect who didn't reach his ceiling (which is normal and expected).

---

## üôè Key Learnings

1. **Peak-age filtering was critical** - Comparing prospect peaks to all-age MLB data was creating noise
2. **Component separation matters** - Mapping Stuff/Control/HRA separately is more accurate than single FIP
3. **Extreme projections are OK** - When scouting says "generational at everything," extreme math results are correct
4. **Distribution > Individual accuracy** - For ceiling projections, group alignment is the right metric
5. **Level-weighted IP insight** - User identified that 149 IP at different levels should be weighted differently

---

## üìö Data Sources

**MLB Performance Data:** 2015-2020, ages 25-29, 50+ IP minimum
**Peak-Age Extremes Observed:**
- Best FIP: 2.57 (Player 11489, 2020)
- Best K/9: 9.79
- Best BB/9: 0.89
- Best HR/9: 0.2 (Dave Larocque, 123 IP, 2020)

**Validation Data:** 2017 prospects ‚Üí 2021 outcomes

---

**End of Summary**

This represents a complete rebuild of the TFR system with a clear philosophy, solid validation, and production-ready implementation. The remaining 2% can be addressed during final pre-1.0 testing based on real-world usage patterns.
